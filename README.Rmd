---
title: "US tariffs on China"
author: "Mitsuo Shiota"
date: "2019-04-17"
output: 
  github_document:
    toc: TRUE
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
Updated: `r Sys.Date()`

I began to use censusapi package.

I added a category "excl" which are excluded from imposed tariffs by USTR.

I added an analysis of Chinese retariation tariff lists in [another page](China-hits-back3.md).

I added an analysis of who pays tariffs in [another page](Who-pays.md).

## Summary

- [Chinese shares in US imports in tariff imposed goods and others in pdf](output/chinese-shares.pdf)
- [Chinese shares in HTS 8 digit imports by tariff schedule (2018) in pdf](output/chinese-shares2.pdf)

I extract 8 digit HTS (Harmonized Tariff Scedule of the United States) codes from the three USTR documents (pdf format). I also extract 10 digit HTS codes from granted product exclusion lists. These lists can be found on [this USTR page](https://ustr.gov/issue-areas/enforcement/section-301-investigations/tariff-actions).

Next, I get data via API from [Census Bureau U.S. International Trade Data](https://www.census.gov/foreign-trade/data/), and confirm the each list is  really worth 34, 16 and 200 billion dollars respectively.

I calculate the Chinese shares on those tariff-imposed goods, excluded goods and not-imposed goods, and look at the shares movements from January 2017 to now to know how much trade diversion is going. I also draw a boxplot of Chinese shares in HTS 10 digit imports in 2018.

## Libraries and functions

As usual, I attach tidyverse package. Although I don't attach, I use pdftools package to read pdf files, keyring package to input API Key, and httr package to get data from URL. As I have found that censusapi package works, I use it.

```{r libraries, include=FALSE}
library(tidyverse)

```

I make functions to facilitate data transformation and acquisition.

```{r self-made functions, echo=FALSE}
# transform df to 4 column df of time, hs10, hs8 and value
sum2hs8 <- function(df) {
    df$GEN_CIF_MO <- as.numeric(df$GEN_CIF_MO)
    
    df$time <- as.Date(paste0(df$time, "-01"), "%Y-%m-%d")
    
    df %>% 
      rename(hs10 = I_COMMODITY,
             value = GEN_CIF_MO) %>% 
      mutate(
        hs8 = str_sub(hs10, end = -3L) # cut codes from 10 to 8 digits
      ) %>% 
      select(time, hs10, hs8, value) %>% 
      arrange(hs10, time)
  }

# get country import data by year
import_from_country <- function(country, year) {
  df <- censusapi::getCensus(
    name = "timeseries/intltrade/imports/hs",
    key = keyring::key_get("census"),
    vars = c("GEN_CIF_MO", "I_COMMODITY"),
    time = year,
    CTY_CODE = country,
    COMM_LVL = "HS10"
    )

  df %>% 
    sum2hs8()
}

# get total import data by year
import_total <- function(year) {
  df <- censusapi::getCensus(
    name = "timeseries/intltrade/imports/hs",
    key = keyring::key_get("census"),
    vars = c("GEN_CIF_MO", "I_COMMODITY"),
    time = year,
    COMM_LVL = "HS10",
    SUMMARY_LVL2="HS"
    )
  
  df %>% 
    sum2hs8()
}

# extract hts codes from specified pages in url and page_range
extract_hts <- function(hts, url, page_range = NULL) {
  tf <- tempfile(fileext = ".pdf")
  
  httr::GET(url, httr::write_disk(tf))
  
  text <- pdftools::pdf_text(tf)
  
  if (!is.null(page_range)) {
    text <- text[page_range]
  }
  
  text %>% 
    str_extract_all(hts) %>% 
    unlist() %>% 
    str_replace_all("\\.", "")
}

```

## Extract HTS 8 digit codes from USTR lists

pdftools::pdf_text lets me scan a pdf file by page. stringr package in tidyverse helps me to extract 8 digits.

```{r extract_digits, echo=FALSE, results="hide", cache=FALSE}
hts8 <- "([0-9]{4})[.]([0-9]{2})[.]([0-9]{2})"

# First tranche 34 billion dollars, 25 percent, effective on July 6, 2018
# https://ustr.gov/issue-areas/enforcement/section-301-investigations/section-301-china/34-billion-trade-action

df_list_34b <- tibble(
  trf_34b = TRUE,
  hs8 = extract_hts(
    hts = hts8,
    url = "https://ustr.gov/sites/default/files/2018-13248.pdf",
    page_range = 5:9
    )
  )

# Second tranche 16 billion dollars, 25 percent, August 23, 2018
# https://ustr.gov/issue-areas/enforcement/section-301-investigations/section-301-china/16-billion-trade-action

df_list_16b <- tibble(
  trf_16b = TRUE,
  hs8 = extract_hts(
    hts = hts8,
    url = "https://ustr.gov/sites/default/files/enforcement/301Investigations/2018-17709.pdf",
    page_range = 4:5
    )
  )

# 200 billion dollars, 10 percent, September 24, 2018
# https://ustr.gov/issue-areas/enforcement/section-301-investigations/section-301-china/200-billion-trade-action

df_list_200b <- tibble(
  trf_200b = TRUE,
  hs8 = extract_hts(
    hts = hts8,
    url = "https://ustr.gov/sites/default/files/enforcement/301Investigations/Tariff%20List%20%2883%20FR%2047974%2C%20as%20amended%20and%20modified%20by%2083%20FR%2049153%29.pdf",
    page_range = 1:194
    )
  )

# 15 percent, September 1, 2019
df_list_300b_a <- tibble(
  trf_300b_a = TRUE,
  hs8 = extract_hts(
    hts = hts8,
    url = "https://ustr.gov/sites/default/files/enforcement/301Investigations/Notice_of_Modification_%28List_4A_and_List_4B%29.pdf",
    page_range = 4:25
    )
  )

# 15 percent, December 15, 2019
df_list_300b_c <- tibble(
  trf_300b_c = TRUE,
  hs8 = extract_hts(
    hts = hts8,
    url = "https://ustr.gov/sites/default/files/enforcement/301Investigations/Notice_of_Modification_%28List_4A_and_List_4B%29.pdf",
    page_range = 142:145
    )
  )

```

USTR says the numbers of HTS 8 digit items are 818, 279 and 5745 for the first tranche 34b, the second tranche 16b and the last 200b, respectively. My caluculation says the numbers are `r nrow(df_list_34b)`, `r nrow(df_list_16b)` and `r nrow(df_list_200b)`. Although there are small differences, I think I can ignore.

## Extract HTS 10 digit codes from exclusion lists

USTR announces exclusions periodically. Exclusions are specified by HTS 10 digit codes.

```{r exclusions, echo=FALSE, results="hide", cache=FALSE}
hts10 <- "([0-9]{4})[.]([0-9]{2})[.]([0-9]{4})"

exclusion_list <- vector("list", length = 13)

# 34b: granted December 21, 2018
exclusion_list[[1]] <- extract_hts(
  hts = hts10,
  url = "https://ustr.gov/sites/default/files/enforcement/301Investigations/2018-28277.pdf",
  page_range = 3:5
  )

# granted March 25, 2019
exclusion_list[[2]] <- extract_hts(
  hts = hts10,
  url = "https://ustr.gov/sites/default/files/enforcement/301Investigations/84_FR_11152.pdf",
  page_range = 3:6
  )

# granted April 18, 2019
exclusion_list[[3]] <- extract_hts(
  hts = hts10,
  url = "https://ustr.gov/sites/default/files/enforcement/301Investigations/84_FR_16310.pdf",
  page_range = 3:5
  )

# granted May 14, 2019
exclusion_list[[4]] <- extract_hts(
  hts = hts10,
  url = "https://ustr.gov/sites/default/files/enforcement/301Investigations/84_FR_21389.pdf",
  page_range = 2:3
  )

# granted June 4, 2019
exclusion_list[[5]] <- extract_hts(
  hts = hts10,
  url = "https://ustr.gov/sites/default/files/enforcement/301Investigations/84_FR_25895.pdf",
  page_range = 2:4
  )

# granted July 9, 2019
exclusion_list[[6]] <- extract_hts(
  hts = hts10,
  url = "https://ustr.gov/sites/default/files/enforcement/301Investigations/Notice_of_Product_Exclusions.pdf",
  page_range = 3:5
  )

# granted September 20, 2019
exclusion_list[[7]] <- extract_hts(
  hts = hts10,
  url = "https://ustr.gov/sites/default/files/enforcement/301Investigations/%2434_Billion_Exclusions_Granted_September.pdf",
  page_range = 3:26
  )

# granted October 2, 2019
exclusion_list[[8]] <- extract_hts(
  hts = hts10,
  url = "https://ustr.gov/sites/default/files/enforcement/301Investigations/%2434_Billion_Exclusions_Granted_October_2019.pdf",
  page_range = 3:12
  )

# 16b: granted July 31, 2019
exclusion_list[[9]] <- extract_hts(
  hts = hts10,
  url = "https://ustr.gov/sites/default/files/enforcement/301Investigations/16_Billion_Exclusions_Granted.pdf",
  page_range = 2:4
  )

# 16b: granted September 20, 2019
exclusion_list[[10]] <- extract_hts(
  hts = hts10,
  url = "https://ustr.gov/sites/default/files/enforcement/301Investigations/%2416_Billion_Exclusions_Granted_September.pdf",
  page_range = 3:11
  )

# 16b: granted October 2, 2019
exclusion_list[[11]] <- extract_hts(
  hts = hts10,
  url = "https://ustr.gov/sites/default/files/enforcement/301Investigations/%2416_Billion_Exclusions_Granted_October_2019.pdf",
  page_range = 3:13
  )

# 200b: granted August 2, 2019
exclusion_list[[12]] <- extract_hts(
  hts = hts10,
  url = "https://ustr.gov/sites/default/files/enforcement/301Investigations/200_Billion_Exclusions_Granted.pdf",
  page_range = 6:7
  )

# 200b: granted September 20, 2019
exclusion_list[[13]] <- extract_hts(
  hts = hts10,
  url = "https://ustr.gov/sites/default/files/enforcement/301Investigations/%24200_Billion_Exclusions_Granted_September.pdf",
  page_range = 3:6
  )


df_list_excl <- tibble(
  trf_excl = TRUE,
  hs10 = exclusion_list %>% unlist() %>% unique()
  ) %>% 
  arrange(hs10)


# save
save(df_list_34b, df_list_16b, df_list_200b,
     df_list_300b_a, df_list_300b_c, df_list_excl, 
     file = "data/tariff_list.rdata")

# load("data/tariff_list.rdata")

```

## Get international trade data, and confirm USTR claims

Following the recommendation in [Internatinal Trade Data API User Guide](https://www.census.gov/foreign-trade/reference/guides/Guide%20to%20International%20Trade%20Datasets.pdf) provided by the US Census Bureau, I register API Key. keyring package allows me to input API Key, and use it, without making it public.

```{r API_Key_input, include=FALSE}
keyring::key_set("census")

```

I struggle with which table I should use, and reach [this page](https://www.census.gov/data/developers/data-sets/international-trade.html). Next I struggle with which variables I should use, and reach [this page](https://api.census.gov/data/timeseries/intltrade/imports/hs/variables.html). I experiment a little, and know that GEN_CIF_MO = GEN_VAL_MO + GEN_CHA_MO. Looks like CIF basis = FOB basis + Freight, insurance and other charges. I choose GEN_CIF_MO as import value.

I get to know the country code of China is 5700 from [this page](https://www.census.gov/foreign-trade/schedules/c/countryname.html). OK, let us get data. Each download takes approximately half a minute.

```{r china_2018, echo=FALSE, warning=FALSE, cache=FALSE}
df_china <- import_from_country(country = 5700,
                              year = "from 2017 to 2019")

df2018 <- df_china %>% 
  filter(time >= "2018-01-01", time <= "2018-12-01")

real34b <- df2018 %>% 
  semi_join(df_list_34b, by = "hs8") %>% 
  summarize(sum = sum(value)) %>% 
  as.numeric()

real16b <- df2018 %>% 
  semi_join(df_list_16b, by = "hs8") %>% 
  summarize(sum = sum(value)) %>% 
  as.numeric()

real200b <- df2018 %>% 
  semi_join(df_list_200b, by = "hs8") %>% 
  summarize(sum = sum(value)) %>% 
  as.numeric()

real300b_a <- df2018 %>% 
  semi_join(df_list_300b_a, by = "hs8") %>% 
  summarize(sum = sum(value)) %>% 
  as.numeric()

real300b_c <- df2018 %>% 
  semi_join(df_list_300b_c, by = "hs8") %>% 
  summarize(sum = sum(value)) %>% 
  as.numeric()

```

Using the tariff lists of 8 digit HTS codes I extracted before, I check if 2018 imports are really worth as much as 34, 16 and 200 billion dollars as USTR claims. According to my calculation, 2018 imports are `r round(real34b/1000000000, 1)`, `r round(real16b/1000000000, 1)` and `r round(real200b/1000000000, 1)` billion dollars. Ratios to the USTR claims are `r round(real34b/1000000000/34, 2)`, `r round(real16b/1000000000/16, 2)` and `r round(real200b/1000000000/200, 2)`.  Little bit smaller, but basically confirm the USTR claims.

2018 imports in List 4 Annex A ("300b_a", effective on September 1, 2019) and Annex C ("300b_c", will be effective on December 15, 2019) are `r round(real300b_a/1000000000, 1)` and `r round(real300b_c/1000000000, 1)` billion dollars respectively.

## How much imports are excluded so far?

```{r how_much_excluded, echo=FALSE}
real_excl <- df2018 %>% 
  semi_join(df_list_excl, by = "hs10") %>% 
  summarize(sum = sum(value)) %>% 
  as.numeric()

```
So far USTR announced exclusion lists `r length(exclusion_list)` times. They specify products simply by HTS 10 digit code, or by product description and HTS 10 digit code it belong to. When I caluculate simply by HTS 10 digit code, exclusions amount to `r round(real_excl/1000000000, 1)` billion dollars annually.

## Look at the Chinese share movements

I get imports from China and total imports from January 2017 up to now, and calculate Chinese shares in imports in each category that is "34b", "16b", "200b" imposed tariffs effective on July 6, 2018, August 23, 2018, and September 24, 2018, "excl" which is excluded, and "the rest" which is not imposed tariffs.

What can I say from the chart below?

1. Chinese shares are the lowest in 34b, next lowest in 16b, higher in 200b, even higher in 300b_a and much much higer in 300b_c, exactly the same order of imposing tariffs. Actually USTR states that they separate 300b into 300b_a and 300b_c based on whether the Chinese shares are less than 75 percent or not in [this page](https://ustr.gov/sites/default/files/enforcement/301Investigations/Notice_of_Modification_%28List_4A_and_List_4B%29.pdf). USTR tends to choose lower Chinese share goods to impose tariffs first to avoid supply chain distruptions.

1. In both 34b and 16b, Chinese shares rise just before the effective date, and decline thereafter. This pattern reflects that importers rush before and flee after.

1. In 200b, I can see the small same pattern, but see bigger rise in December 2018 just before the tariff rates were scheduled to rise from 10 to 25 percent, and bigger decline thereafter. Looks like importers care little of 10 percent, but care much of 25 percent.

1. In the tariff imposed goods, Chinese shares are declining. This means other countries' shares are rising. Trade diversion is going on.

1. Seasonality is observed. Chinese shares fall around March every year, as Chinese take long vacations when their New Year begins around February.

1. Chinese shares in "excl" have declined. We will see recovery after exclusion.

```{r get_data, echo=FALSE, cache=FALSE, fig.width=6, fig.height=6}
# Total import
# get data, takes time
df_total <- import_total("from 2017 to 2019")

# value.x as total, value.y as china
df_total <- df_total %>% 
  left_join(df_china, by = c("hs10", "time")) %>% 
  select(-hs8.y) %>% 
  rename(hs8 = hs8.x)

# add category
df_total <- df_total %>% 
  left_join(df_list_34b, by = "hs8") %>% 
  left_join(df_list_16b, by = "hs8") %>% 
  left_join(df_list_200b, by = "hs8") %>% 
  left_join(df_list_300b_a, by = "hs8") %>% 
  left_join(df_list_300b_c, by = "hs8") %>% 
  left_join(df_list_excl, by = "hs10") %>% 
  replace_na(list(
    trf_34b = FALSE,
    trf_16b = FALSE,
    trf_200b = FALSE,
    trf_300b_a = FALSE,
    trf_300b_c = FALSE,
    trf_excl = FALSE
  )) %>% 
  mutate(
    category_old = if_else(trf_34b, "34b",
                       if_else(trf_16b, "16b",
                               if_else(trf_200b, "200b",
                                       if_else(trf_300b_a, "300b_a",
                                               if_else(trf_300b_c, "300b_c", "rest"))))),
    category = if_else(trf_excl, "excl", category_old)
  ) %>% 
  select(-starts_with("trf_"), -category_old) %>% 
  rename(
    total = value.x,
    china = value.y
  ) %>% 
  replace_na(list(china = 0))

# Calculate share by category and month
df_total %>% 
  group_by(category, time) %>% 
  summarize(
    total = sum(total),
    china = sum(china),
    share = china / total * 100,
  ) %>% 
  ggplot(aes(x = time, y = share, color = fct_reorder2(category, time, share))) +
  geom_line(size = 1) +
  labs(
    title = "Chinese shares in US imports",
    x = "",
    y = "percent",
    color = "category"
  )

ggsave(filename = "output/chinese-shares.pdf",
       width = 6, height = 6, units = "in", dpi = 300)

```

To confirm the point #1 above, I draw the distribution of 2018 Chinese shares in HTS 10 digit goods by each tariff schedule category. Chinese shares in "excl" are much higher than "34b", "16b" and "200b" from which "excl" is excluded. As the shares in "300b_c" (will be effective on December 15, 2019) are much much higer than those of "excl", USTR will receive massive product exclusion requests.

```{r boxplot, echo=FALSE, warning=FALSE, fig.width=6, fig.height=6}
df_total$category <- factor(df_total$category, 
                            levels = c("34b", "16b", "200b", "300b_a", "300b_c", "excl","rest"))

df_total %>% 
  filter(time >= "2018-01-01", time <= "2018-12-01") %>% 
  group_by(category, hs10) %>% 
  summarize(
    total = sum(total),
    china = sum(china),
    share = china / total * 100,
  ) %>% 
  ggplot(aes(x = category, y = share)) +
  geom_boxplot() +
  labs(
    title = "Chinese shares by tariff schedule (2018)",
    x = "",
    y = "percent"
  )

ggsave(filename = "output/chinese-shares2.pdf",
       width = 6, height = 6, units = "in", dpi = 300)

```

EOL
